{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c773614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from scipy.sparse import vstack, csr_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d37bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\Projetos\\llm_security\\dataset'\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\",\n",
    "    \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "    \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\",\n",
    "    \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "    \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "    \"dst_host_srv_rerror_rate\", \"label\", \"difficulty_level\"\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv(f'{path}/Train.txt', delimiter=',', header=None, names=column_names)\n",
    "test_df = pd.read_csv(f'{path}/Test.txt', delimiter=',', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81813207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert dataset flags to Scapy-compatible flags\n",
    "def convert_flag_to_scapy(flag):\n",
    "    flag_translation = {\n",
    "        'REJ': 'R',\n",
    "        'SF': 'PA',\n",
    "        'S0': 'S',\n",
    "        'RSTO': 'R',\n",
    "        'S1': 'S',\n",
    "        'S2': 'S',\n",
    "        'S3': 'S',\n",
    "        'RSTOS0': 'R',\n",
    "        'OTH': ''\n",
    "    }\n",
    "    return ''.join([flag_translation.get(f, '') for f in flag])\n",
    "\n",
    "# Apply the flag conversion to the 'flag' column\n",
    "train_df['flag'] = train_df['flag'].apply(convert_flag_to_scapy)\n",
    "test_df['flag'] = test_df['flag'].apply(convert_flag_to_scapy)\n",
    "\n",
    "# Convert the multi-class labels into binary labels: 1 for any attack, 0 for normal\n",
    "train_df['binary_label'] = (train_df['label'] != 'normal').astype(int)\n",
    "test_df['binary_label'] = (test_df['label'] != 'normal').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(f'{path}/train_net.parquet')\n",
    "test_df.to_parquet(f'{path}/test_net.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ea7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(f'{path}/train_net.parquet')\n",
    "test_df = pd.read_parquet(f'{path}/test_net.parquet')\n",
    "\n",
    "# Selecting only the necessary features\n",
    "features_to_use = ['protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes']\n",
    "categorical_features = ['protocol_type', 'service', 'flag']\n",
    "numerical_features = ['src_bytes', 'dst_bytes']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # This drops the columns that are not explicitly transformed\n",
    ")\n",
    "\n",
    "# Apply preprocessing to both training and testing data\n",
    "X_train = preprocessor.fit_transform(train_df[features_to_use])\n",
    "X_test = preprocessor.transform(test_df[features_to_use])\n",
    "\n",
    "# Convert to CSR format for models that require it\n",
    "X_train_csr = csr_matrix(X_train)\n",
    "X_test_csr = csr_matrix(X_test)\n",
    "\n",
    "# Convert to dense format for deep learning models\n",
    "X_train_dense = X_train_csr.toarray()\n",
    "X_test_dense = X_test_csr.toarray()\n",
    "\n",
    "# Labels for training and testing\n",
    "y_train = train_df['binary_label']\n",
    "y_test = test_df['binary_label']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_inatel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
